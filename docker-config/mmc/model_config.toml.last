[inner]
version = "1.11.0"

# ========================================
# ç¡…åŸºæµåŠ¨å…¨å…è´¹é…ç½®æ–¹æ¡ˆ
# ========================================
# ç”¨é€”ï¼šæ‰€æœ‰æ¨¡å‹éƒ½ä½¿ç”¨ç¡…åŸºæµåŠ¨çš„å…è´¹æ¨¡å‹
# ä¼˜åŠ¿ï¼šå®Œå…¨å…è´¹ï¼Œé›¶æˆæœ¬ä½¿ç”¨
# é™åˆ¶ï¼šæ¨¡å‹æ€§èƒ½ä¸å¦‚ä»˜è´¹æ¨¡å‹
# ========================================

[[api_providers]]
name = "GLM"
base_url = "https://open.bigmodel.cn/api/paas/v4"
api_key = "89a2bbde7e784556a0bd2ba1b6403e53.JIYEhnC8GNmW3qte"
client_type = "openai"
max_retry = 2
timeout = 60
retry_interval = 2

[[api_providers]]
name = "SiliconFlow"
base_url = "https://api.siliconflow.cn/v1"
api_key = "sk-idjdrtdithcxuozmairymdebbovithfcidkvnavnchwnxavh"  # â† æ›¿æ¢æˆä½ çš„API Key
client_type = "openai"
max_retry = 3
timeout = 120
retry_interval = 5

[[api_providers]]
name = "DeepSeek"
base_url = "https://api.deepseek.com"
api_key = "sk-d38850098a9540b7a88ded9e311f2a46"
client_type = "openai"
max_retry = 3
timeout = 120
retry_interval = 5

# ========================================
# æ¨¡å‹å®šä¹‰ï¼ˆä»…å…è´¹æ¨¡å‹ï¼‰
# ========================================

# ==================== GLM æ¨¡å‹ ====================
[[models]]
model_identifier = "glm-4"
name = "glm-4"
api_provider = "GLM"
price_in = 0
price_out = 0
force_stream_mode = false

[[models]]
model_identifier = "glm-4-plus"
name = "glm-4-plus"
api_provider = "GLM"
price_in = 0
price_out = 0
force_stream_mode = false

[[models]]
model_identifier = "glm-4v-plus"
name = "glm-4v-plus"
api_provider = "GLM"
price_in = 0
price_out = 0
force_stream_mode = false

[[models]]
model_identifier = "glm-4-air"
name = "glm-4-air"
api_provider = "GLM"
price_in = 0
price_out = 0
force_stream_mode = false

# ==================== ç¡…åŸºæµåŠ¨ - å…è´¹æ–‡æœ¬æ¨¡å‹ ====================

# Qwen2.5-7B-Instructï¼ˆå®Œå…¨å…è´¹ï¼Œæ¨èï¼‰
[[models]]
model_identifier = "Qwen/Qwen2.5-7B-Instruct"
name = "Qwen/Qwen2.5-7B-Instruct"
api_provider = "SiliconFlow"
price_in = 0
price_out = 0
force_stream_mode = false

# Qwen2-7B-Instructï¼ˆå®Œå…¨å…è´¹ï¼‰
[[models]]
model_identifier = "Qwen/Qwen2-7B-Instruct"
name = "Qwen/Qwen2-7B-Instruct"
api_provider = "SiliconFlow"
price_in = 0
price_out = 0
force_stream_mode = false

# GLM-4-9Bï¼ˆå®Œå…¨å…è´¹ï¼‰
[[models]]
model_identifier = "THUDM/glm-4-9b-chat"
name = "THUDM/glm-4-9b-chat"
api_provider = "SiliconFlow"
price_in = 0
price_out = 0
force_stream_mode = false

# ==================== ç¡…åŸºæµåŠ¨ - å…è´¹è§†è§‰æ¨¡å‹ ====================

# PaddleOCR-VLï¼ˆå®Œå…¨å…è´¹ï¼ŒOCRä¸“ç”¨ï¼‰
[[models]]
model_identifier = "PaddlePaddle/PaddleOCR-VL"
name = "PaddlePaddle/PaddleOCR-VL"
api_provider = "SiliconFlow"
price_in = 0
price_out = 0
force_stream_mode = false

# Qwen2-VL-7B-Instructï¼ˆè¶…ä¾¿å®œï¼Œæ¥è¿‘å…è´¹ï¼‰
[[models]]
model_identifier = "Qwen/Qwen2-VL-7B-Instruct"
name = "Qwen/Qwen2-VL-7B-Instruct"
api_provider = "SiliconFlow"
price_in = 0.5
price_out = 2
force_stream_mode = false

# ==================== DeepSeek å®˜æ–¹æ¨¡å‹ï¼ˆå¤‡ç”¨ï¼‰ ====================
[[models]]
model_identifier = "deepseek-chat"
name = "deepseek-chat"
api_provider = "DeepSeek"
price_in = 0
price_out = 0
force_stream_mode = false

[[models]]
model_identifier = "deepseek-vl"
name = "deepseek-vl"
api_provider = "DeepSeek"
price_in = 0
price_out = 0
force_stream_mode = false

# ========================================
# ä»»åŠ¡é…ç½®ï¼ˆå…¨éƒ¨ä½¿ç”¨å…è´¹æ¨¡å‹ï¼‰
# ========================================

[models.extra_params]

# å·¥å…·ä»»åŠ¡ï¼ˆä½¿ç”¨Qwen2.5-7Bå…è´¹æ¨¡å‹ï¼‰
[model_task_config.utils]
model_list = ["Qwen/Qwen2.5-7B-Instruct"]
temperature = 0.2
max_tokens = 2000
slow_threshold = 10
selection_strategy = "random"

# å·¥å…·è°ƒç”¨ï¼ˆä½¿ç”¨GLM-4-9Bå…è´¹æ¨¡å‹ï¼‰
[model_task_config.tool_use]
model_list = ["THUDM/glm-4-9b-chat"]
temperature = 0.5
max_tokens = 2000
slow_threshold = 8
selection_strategy = "random"

# å›å¤ç”Ÿæˆï¼ˆä½¿ç”¨Qwen2.5-7Bå…è´¹æ¨¡å‹ï¼‰
[model_task_config.replyer]
model_list = ["Qwen/Qwen2.5-7B-Instruct"]
temperature = 0.3
max_tokens = 2000
slow_threshold = 15
selection_strategy = "random"

# è§„åˆ’ä»»åŠ¡ï¼ˆä½¿ç”¨GLM-4-9Bå…è´¹æ¨¡å‹ï¼‰
[model_task_config.planner]
model_list = ["THUDM/glm-4-9b-chat"]
temperature = 0.3
max_tokens = 2000
slow_threshold = 10
selection_strategy = "random"

# è§†è§‰ç†è§£ï¼ˆä½¿ç”¨å…è´¹OCRï¼‰
[model_task_config.vlm]
model_list = ["PaddlePaddle/PaddleOCR-VL", "Qwen/Qwen2-VL-7B-Instruct"]
max_tokens = 2000
slow_threshold = 15
selection_strategy = "random"

# è¯­éŸ³å¤„ç†ï¼ˆä½¿ç”¨Qwen2.5-7Bå…è´¹æ¨¡å‹ï¼‰
[model_task_config.voice]
model_list = ["Qwen/Qwen2.5-7B-Instruct"]
slow_threshold = 10
selection_strategy = "random"

# å‘é‡åŒ–ï¼ˆä½¿ç”¨Qwen2.5-7Bå…è´¹æ¨¡å‹ï¼‰
[model_task_config.embedding]
model_list = ["Qwen/Qwen2.5-7B-Instruct"]
slow_threshold = 5
selection_strategy = "random"

# çŸ¥è¯†å›¾è°±å®ä½“æŠ½å–ï¼ˆä½¿ç”¨å…è´¹æ¨¡å‹ï¼‰
[model_task_config.lpmm_entity_extract]
model_list = ["Qwen/Qwen2.5-7B-Instruct"]
temperature = 0.2
max_tokens = 2000
slow_threshold = 15
selection_strategy = "random"

# çŸ¥è¯†å›¾è°±RDFæ„å»ºï¼ˆä½¿ç”¨å…è´¹æ¨¡å‹ï¼‰
[model_task_config.lpmm_rdf_build]
model_list = ["Qwen/Qwen2.5-7B-Instruct"]
temperature = 0.2
max_tokens = 2000
slow_threshold = 15
selection_strategy = "random"

# çŸ¥è¯†å›¾è°±é—®ç­”ï¼ˆä½¿ç”¨Qwen2.5-7Bå…è´¹æ¨¡å‹ï¼‰
[model_task_config.lpmm_qa]
model_list = ["Qwen/Qwen2.5-7B-Instruct"]
temperature = 0.7
max_tokens = 2000
slow_threshold = 15
selection_strategy = "random"

# æƒ…æ„Ÿåˆ†æï¼ˆä½¿ç”¨å…è´¹æ¨¡å‹ï¼‰
[model_task_config.emotion]
model_list = ["Qwen/Qwen2.5-7B-Instruct"]
temperature = 0.5
max_tokens = 2000
slow_threshold = 10
selection_strategy = "random"

# å°å·¥å…·ä»»åŠ¡ï¼ˆä½¿ç”¨å…è´¹æ¨¡å‹ï¼‰
[model_task_config.utils_small]
model_list = ["Qwen/Qwen2.5-7B-Instruct"]
temperature = 0.3
max_tokens = 2000
slow_threshold = 10
selection_strategy = "random"

# å°è§„åˆ’ä»»åŠ¡ï¼ˆä½¿ç”¨GLM-4-9Bå…è´¹æ¨¡å‹ï¼‰
[model_task_config.planner_small]
model_list = ["THUDM/glm-4-9b-chat"]
temperature = 0.3
max_tokens = 2000
slow_threshold = 10
selection_strategy = "random"


# ========================================
# å…è´¹æ¨¡å‹è¯´æ˜
# ========================================
#
# ã€å®Œå…¨å…è´¹æ¨¡å‹ã€‘
# 1. Qwen/Qwen2.5-7B-Instruct â­ æ¨è
#    - é€šä¹‰åƒé—®2.5ï¼Œ70äº¿å‚æ•°
#    - æ€§èƒ½å‡è¡¡ï¼Œé€‚åˆå¤§å¤šæ•°ä»»åŠ¡
#    - å®Œå…¨å…è´¹ï¼Œæ— é™åˆ¶ä½¿ç”¨
#
# 2. Qwen/Qwen2-7B-Instruct
#    - é€šä¹‰åƒé—®2.0ï¼Œ70äº¿å‚æ•°
#    - ç¨³å®šå¯é ï¼ŒåŸºç¡€ä»»åŠ¡è¶³å¤Ÿ
#    - å®Œå…¨å…è´¹ï¼Œæ— é™åˆ¶ä½¿ç”¨
#
# 3. THUDM/glm-4-9b-chat
#    - æ™ºè°±GLM-4ï¼Œ90äº¿å‚æ•°
#    - ä¸­æ–‡èƒ½åŠ›å¼ºï¼Œé€‚åˆå¯¹è¯
#    - å®Œå…¨å…è´¹ï¼Œæ— é™åˆ¶ä½¿ç”¨
#
# 4. deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
#    - DeepSeek R1è’¸é¦ç‰ˆï¼Œ70äº¿å‚æ•°
#    - æ¨ç†èƒ½åŠ›å¼ºï¼Œé€‚åˆå¤æ‚ä»»åŠ¡
#    - å®Œå…¨å…è´¹ï¼Œæ— é™åˆ¶ä½¿ç”¨
#
# 5. PaddlePaddle/PaddleOCR-VL â­ è§†è§‰ä¸“ç”¨
#    - é£æ¡¨OCRï¼Œä¸“é—¨è¯†åˆ«æ–‡å­—
#    - æ–‡æ¡£è§£æã€è¡¨æ ¼è¯†åˆ«
#    - å®Œå…¨å…è´¹ï¼Œæ— é™åˆ¶ä½¿ç”¨
#
# ã€æ¥è¿‘å…è´¹æ¨¡å‹ã€‘
# 6. Qwen/Qwen2-VL-7B-Instruct
#    - é€šä¹‰åƒé—®è§†è§‰æ¨¡å‹
#    - è¾“å…¥Â¥0.5/ç™¾ä¸‡ï¼Œè¾“å‡ºÂ¥2/ç™¾ä¸‡
#    - éå¸¸ä¾¿å®œï¼Œæ¨èä½¿ç”¨
#
# ========================================
# ã€ä½¿ç”¨å»ºè®®ã€‘
# ========================================
#
# âœ… æ¨èåœºæ™¯ï¼š
# - ä¸ªäººå­¦ä¹ ã€æµ‹è¯•ã€å¼€å‘
# - é¢„ç®—æœ‰é™çš„é¡¹ç›®
# - è½»é‡çº§åº”ç”¨ï¼ˆæ—¥å‡<1000æ¡æ¶ˆæ¯ï¼‰
# - å¯¹æ€§èƒ½è¦æ±‚ä¸æç«¯çš„åœºæ™¯
#
# âŒ ä¸æ¨èåœºæ™¯ï¼š
# - é«˜å¹¶å‘ç”Ÿäº§ç¯å¢ƒ
# - å¯¹è´¨é‡è¦æ±‚æé«˜çš„åœºæ™¯
# - å¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆå…è´¹æ¨¡å‹èƒ½åŠ›æœ‰é™ï¼‰
#
# ğŸ’¡ æ€§èƒ½å¯¹æ¯”ï¼š
# - å…è´¹æ¨¡å‹ vs DeepSeek-V3: çº¦70-80%æ€§èƒ½
# - Qwen2.5-7B: æ€§ä»·æ¯”æœ€é«˜ï¼Œæ¨èä¸»ç”¨
# - R1è’¸é¦ç‰ˆ: æ¨ç†èƒ½åŠ›å¼ºï¼Œé€‚åˆå¤æ‚ä»»åŠ¡
# - PaddleOCR: OCRè¯†åˆ«æ•ˆæœå¥½
#
# ğŸ’° æˆæœ¬ä¼˜åŠ¿ï¼š
# - å®Œå…¨å…è´¹ï¼šÂ¥0/æœˆ
# - å³ä½¿ä½¿ç”¨Qwen2-VLä¹Ÿå¾ˆä¾¿å®œï¼š<Â¥5/æœˆ
# - æ¯”DeepSeekå®˜æ–¹ä¾¿å®œï¼ˆé•¿æœŸï¼‰
#
# ========================================
