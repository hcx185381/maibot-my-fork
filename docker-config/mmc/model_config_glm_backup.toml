[inner]
version = "1.11.0"

# 配置文件版本号迭代规则同bot_config.toml

[[api_providers]]
name = "GLM"
base_url = "https://open.bigmodel.cn/api/paas/v4"
api_key = "89a2bbde7e784556a0bd2ba1b6403e53.JIYEhnC8GNmW3qte"
client_type = "openai"
max_retry = 2
timeout = 60
retry_interval = 2

[[api_providers]]
name = "SiliconFlow"
base_url = "https://api.siliconflow.cn/v1"
api_key = "89a2bbde7e784556a0bd2ba1b6403e53.JIYEhnC8GNmW3qte"
client_type = "openai"
max_retry = 3
timeout = 120
retry_interval = 5

[[api_providers]]
name = "DeepSeek"
base_url = "https://api.deepseek.com"
api_key = "sk-d38850098a9540b7a88ded9e311f2a46"
client_type = "openai"
max_retry = 3
timeout = 120
retry_interval = 5
[[models]]
model_identifier = "glm-4"
name = "glm-4"
api_provider = "GLM"
price_in = 0
price_out = 0
force_stream_mode = false

[models.extra_params]
[model_task_config.utils]
model_list = ["glm-4"]
temperature = 0.2
max_tokens = 2000
slow_threshold = 10
selection_strategy = "random"

[model_task_config.tool_use]
model_list = ["glm-4"]
temperature = 0.5
max_tokens = 2000
slow_threshold = 8
selection_strategy = "random"

[model_task_config.replyer]
model_list = ["glm-4"]
temperature = 0.3
max_tokens = 2000
slow_threshold = 15
selection_strategy = "random"

[model_task_config.planner]
model_list = ["glm-4"]
temperature = 0.3
max_tokens = 2000
slow_threshold = 10
selection_strategy = "random"

[model_task_config.vlm]
model_list = ["glm-4"]
max_tokens = 2000
slow_threshold = 15
selection_strategy = "random"

[model_task_config.voice]
model_list = ["glm-4"]
slow_threshold = 10
selection_strategy = "random"

[model_task_config.embedding]
model_list = ["glm-4"]
slow_threshold = 5
selection_strategy = "random"

[model_task_config.lpmm_entity_extract]
model_list = ["glm-4"]
temperature = 0.2
max_tokens = 2000
slow_threshold = 15
selection_strategy = "random"

[model_task_config.lpmm_rdf_build]
model_list = ["glm-4"]
temperature = 0.2
max_tokens = 2000
slow_threshold = 15
selection_strategy = "random"

[model_task_config.lpmm_qa]
model_list = ["glm-4"]
temperature = 0.7
max_tokens = 2000
slow_threshold = 15
selection_strategy = "random"

[model_task_config.emotion]
model_list = ["glm-4"]
temperature = 0.5
max_tokens = 2000
slow_threshold = 10
selection_strategy = "random"

[model_task_config.utils_small]
model_list = ["glm-4"]
temperature = 0.3
max_tokens = 2000
slow_threshold = 10
selection_strategy = "random"

[model_task_config.planner_small]
model_list = ["glm-4"]
temperature = 0.3
max_tokens = 2000
slow_threshold = 10
selection_strategy = "random"
