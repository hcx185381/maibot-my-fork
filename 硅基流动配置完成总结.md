# 硅基流动 API 配置完成总结

**配置时间**: 2026-02-02
**状态**: ✅ 配置成功并运行

---

## 📋 已配置模型列表

### 文本模型

| 模型名称 | 用途 | 价格 | 说明 |
|---------|------|------|------|
| **deepseek-ai/DeepSeek-V3** | 日常聊天、回复 | ¥2/M in, ¥8/M out | 最强性能，用免费额度 |
| **deepseek-ai/DeepSeek-R1** | 复杂推理、规划 | ¥4/M in, ¥16/M out | 推理专用，用免费额度 |
| **Qwen/Qwen2.5-7B-Instruct** | 工具任务 | 免费 | 快速响应 |

### 视觉模型 (VLM)

| 模型名称 | 用途 | 价格 | 说明 |
|---------|------|------|------|
| **PaddlePaddle/PaddleOCR-VL** | OCR、文档解析 | 完全免费 | 识别文字、表格 |
| **Qwen/Qwen2-VL-7B-Instruct** | 通用视觉理解 | ¥0.5/M in, ¥2/M out | 图片理解、对话 |

---

## 🎯 任务配置策略

| 任务类型 | 使用模型 | 策略 |
|---------|---------|------|
| **utils / 工具任务** | Qwen2.5-7B | 免费模型 |
| **tool_use / 工具调用** | DeepSeek-R1 | 强推理能力 |
| **replyer / 回复生成** | DeepSeek-V3 | 最佳对话质量 |
| **planner / 规划任务** | DeepSeek-R1 | 强推理能力 |
| **vlm / 视觉理解** | PaddleOCR + Qwen2-VL | 免费+便宜组合 |
| **voice / 语音** | DeepSeek-V3 | 高质量输出 |
| **embedding / 向量化** | DeepSeek-V3 | 高质量向量 |

---

## 💰 费用说明

### 免费额度
- **新用户赠送**: 14元（约2000万Tokens）
- **免费模型**: Qwen2.5-7B、PaddleOCR-VL（永久免费）

### 预估费用
根据你的使用量，假设每天100条消息：

| 场景 | 月消耗 | 月费用 |
|------|--------|--------|
| 全部用免费模型 | 0 Tokens | ¥0 |
| 混合使用（70%免费） | ~900万 Tokens | ¥6-10 |
| 全部用付费模型 | ~3000万 Tokens | ¥20-30 |

**建议**: 优先使用免费模型，复杂任务才用付费模型，这样14元额度可以用2-3个月！

---

## ✅ 测试结果

```
测试模型: DeepSeek-V3
状态: ✅ 成功
回复: 1+1的正确答案是 **2**
Token使用: 输入=9, 输出=80

测试模型: PaddleOCR-VL
状态: ✅ 成功
回复: 正常响应
Token使用: 输入=9, 输出=24
```

---

## 🔧 配置文件位置

- **主配置**: `docker-config/mmc/model_config.toml`
- **API提供商**: 第15-22行（SiliconFlow）
- **模型列表**: 第88-135行
- **任务配置**: 第137-222行

---

## 📝 后续建议

### 1. 监控用量
定期检查你的硅基流动控制台，查看Token使用情况和剩余额度

### 2. 优化配置
如果发现某个模型用得太多，可以在 `model_task_config` 中调整

### 3. 备用方案
建议配置多个平台的API Key（如DeepSeek官方、GLM等），这样主平台出问题可以自动切换

### 4. 获取更多免费额度
- 邀请好友注册（双方各得500万Tokens）
- 参与硅基流动的活动
- 关注官方公告获取优惠

---

## 🎉 配置完成！

现在你的MaiBot已经可以使用硅基流动的API了！

**开始使用**: 直接在QQ群里和机器人对话即可

**查看状态**: 访问 http://localhost:8001 （WebUI管理界面）

**查看日志**: `docker logs maim-bot-core -f`

---

**创建时间**: 2026-02-02
**创建工具**: Claude Code
