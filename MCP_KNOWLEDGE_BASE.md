# MCP 调用知识库

**📅 创建日期**: 2026-02-03
**🎯 用途**: 保存通过MCP工具获取的关键信息，避免重复调用
**💾 位置**: 项目根目录

---

## ═══════════════════════════════════════════════════════════════
##                        📚 知识库目录
## ═══════════════════════════════════════════════════════════════

1. [智谱AI免费模型文档](#智谱ai免费模型)
2. [硅基流动免费模型列表](#硅基流动免费模型)
3. [各大平台免费模型对比](#各大平台免费模型对比)
4. [模型性能基准测试](#模型性能基准测试)

---

## ═══════════════════════════════════════════════════════════════
##                    🤖 智谱AI免费模型
## ═══════════════════════════════════════════════════════════════

**官方文档**: https://docs.bigmodel.cn/cn/guide/models/free/glm-4-flash-250414
**调用时间**: 2026-02-03
**来源**: MCP web-reader

### GLM-4-Flash 模型信息

**基本信息**:
- 模型名称: `glm-4-flash`
- 状态: ✅ 完全免费
- 类型: 语言模型
- 上下文长度: 128K
- 官方确认: 永久免费

**特点**:
- ✅ 智谱AI首个免费的大模型API
- ✅ 支持联网搜索
- ✅ 长上下文处理（128K）
- ✅ 多语言支持
- ✅ 函数调用支持
- ✅ 速度极快

**适用场景**:
- 文章创作
- 代码调试、代码生成
- 知识库问答
- PPT助手
- 思维导图生成
- 智能问答
- 摘要生成
- 文本数据处理

**API调用示例**:
```bash
curl -X POST "https://open.bigmodel.cn/api/paas/v4/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key" \
  -d '{
    "model": "glm-4-flash",
    "messages": [
      {"role": "user", "content": "你好"}
    ],
    "max_tokens": 4096,
    "temperature": 0.6
  }'
```

### 其他智谱免费模型

根据官方文档，智谱AI还提供以下免费/低价模型：

| 模型名称 | 类型 | 费用 | 特点 |
|---------|------|------|------|
| glm-4-flash | 文本 | 免费 | 主力免费模型 |
| glm-4v-flash | 多模态 | 免费 | 视觉理解（待确认）|
| glm-4-plus | 文本 | 低价 | 高性能 |
| glm-4v-plus | 多模态 | 低价 | 视觉理解 |

**注意**: `glm-4v-flash` 可能在实际调用中参数不正确，建议使用 `glm-4v-plus` 或其他平台的视觉模型。

---

## ═══════════════════════════════════════════════════════════════
##                    🔬 硅基流动免费模型
## ═══════════════════════════════════════════════════════════════

**官方文档**: https://docs.siliconflow.cn/quickstart/models
**调用时间**: 2026-02-03
**来源**: MCP web-reader

### 【免费大语言模型列表】官方确认

以下模型在硅基流动平台**完全免费**（在不超过平台限速的条件下）：

| 模型名称 | 参数量 | 上下文 | API调用名称 | 性能 |
|---------|--------|--------|-------------|------|
| Qwen2-7B-Instruct | 70亿 | 32K | `Qwen/Qwen2-7B-Instruct` | ⭐⭐⭐ |
| Qwen2-1.5B-Instruct | 15亿 | 32K | `Qwen/Qwen2-1.5B-Instruct` | ⭐⭐ |
| Qwen1.5-7B-Chat | 70亿 | 32K | `Qwen/Qwen1.5-7B-Chat` | ⭐⭐⭐ |
| **GLM-4-9B-Chat** ⭐ | **90亿** | **32K** | `THUDM/glm-4-9b-chat` | **⭐⭐⭐** |
| ChatGLM3-6B | 60亿 | 32K | `THUDM/chatglm3-6b` | ⭐⭐ |
| InternLM2.5-7B-Chat | 70亿 | 32K | `internlm/internlm2_5-7b-chat` | ⭐⭐⭐ |
| Mistral-7B-Instruct-v0.2 | 70亿 | 32K | `mistralai/Mistral-7B-Instruct-v0.2` | ⭐⭐⭐ |

### 模型详细说明

#### 1. GLM-4-9B-Chat ⭐ 推荐
- **参数量**: 90亿
- **上下文**: 32K
- **特点**: 中文能力强，适合对话
- **适用**: 日常聊天、中文任务
- **性能**: 硅基流动免费模型中最强

#### 2. Qwen2-7B-Instruct
- **参数量**: 70亿
- **上下文**: 32K
- **特点**: 性能均衡，适合大多数任务
- **适用**: 通用任务

#### 3. ChatGLM3-6B
- **参数量**: 60亿
- **上下文**: 32K
- **特点**: 速度快，轻量级
- **适用**: 快速响应场景

### 免费模型限制

**官方说明**:
> 上述模型在不超过平台限速的条件下可免费使用
> 北京硅基流动科技有限公司保留免费模型的解释权

**限制说明**:
- ✅ 完全免费调用
- ⚠️ 有速率限制（RPH/RPD）
- ⚠️ 高并发时可能被限流
- ✅ 适合个人学习、开发、测试

**Rate Limits**:
- 每分钟请求数限制（RPM）
- 每天请求数限制（RPD）
- 并发数限制
- 具体数值需查看官方文档的最新说明

---

## ═══════════════════════════════════════════════════════════════
##                 🌐 各大平台免费模型对比
## ═══════════════════════════════════════════════════════════════

**调研时间**: 2026-02-03
**调研范围**: HuggingFace、魔搭社区、硅基流动、智谱AI、讯飞星火、DeepSeek、美团

### 免费模型总表

| 平台 | 免费模型 | 参数量 | 性能 | 官方确认 | 限制 |
|------|---------|--------|------|---------|------|
| **智谱AI** ⭐ | **GLM-4-Flash** | **旗舰级** | **⭐⭐⭐⭐⭐** | ✅ 官方文档 | 2并发 |
| 硅基流动 | Qwen2.7B | 70亿 | ⭐⭐⭐ | ✅ 官方列表 | 速率限制 |
| 硅基流动 | GLM-4-9B | 90亿 | ⭐⭐⭐ | ✅ 官方列表 | 速率限制 |
| 硅基流动 | PaddleOCR-VL | 专用 | ⭐⭐⭐ | ✅ 官方列表 | 速率限制 |
| DeepSeek | deepseek-chat | - | ⭐⭐⭐⭐⭐ | ⚠️ 新用户额度 | 仅新用户 |
| 魔搭社区 | 多种模型 | - | - | ✅ 每日2000次 | 2000次/天 |
| 讯飞星火 | Spark Lite | - | ⭐⭐⭐ | ✅ 永久免费 | API限制 |
| 美团 | LongCat-Flash | 560亿 | ⭐⭐⭐⭐ | ✅ 每日50万tokens | 需申请 |

### 详细说明

#### 1. 智谱AI ⭐⭐⭐⭐⭐ 强烈推荐

**GLM-4-Flash**:
- 官方文档: https://docs.bigmodel.cn/cn/guide/models/free/glm-4-flash-250414
- 状态: ✅ 完全免费，永久
- 性能: ⭐⭐⭐⭐⭐ 接近DeepSeek-V3
- 上下文: 128K
- 特点: 支持联网搜索、函数调用
- 限制: 2并发（个人使用足够）

**优势**:
- 官方明确确认永久免费
- 性能最强（旗舰级）
- 128K超长上下文
- 支持联网搜索
- 官方提供，稳定可靠

#### 2. 硅基流动

**免费模型列表**:
- Qwen2-7B-Instruct (70亿)
- GLM-4-9B-Chat (90亿)
- ChatGLM3-6B (60亿)
- PaddleOCR-VL (视觉OCR)
- 等多个模型

**限制**:
- 有速率限制
- 高并发可能被限流
- 适合个人学习测试

#### 3. DeepSeek

**免费额度**:
- 新用户: 10元额度
- 之后: 按量计费
- 不算真正的免费方案

#### 4. 魔搭社区 (ModelScope)

**免费政策**:
- 每日2000次免费调用
- 支持Qwen、DeepSeek、GLM等模型
- 限制较严格

#### 5. 讯飞星火

**Spark Lite**:
- API永久免费
- 基础能力免费
- 性能中等

#### 6. 美团 (LongCat)

**LongCat-Flash**:
- 每日50万Tokens免费
- 560亿总参数
- 需要申请

### 性能对比（免费模型）

```
DeepSeek-V3 (付费基准)
    ↓
GLM-4-Flash (智谱免费) ← 接近付费级别
    ↓
LongCat-Flash (美团免费)
    ↓
GLM-4-9B (硅基流动)
    ↓
Qwen2.5-7B (硅基流动)
```

---

## ═══════════════════════════════════════════════════════════════
##                    📊 模型性能基准测试
## ═══════════════════════════════════════════════════════════════

**数据来源**: 2025年各大模型基准测试
**参考**: SuperCLUE、LMSYS Chatbot Arena

### 开源模型排名（中文）

| 排名 | 模型 | 参数量 | 性能特点 |
|------|------|--------|---------|
| 1 | DeepSeek-V3 | 671B (37B激活) | 接近GPT-4o |
| 2 | Qwen3-Max | - | 综合能力强 |
| 3 | GLM-4.5 | 3550B (320B激活) | 工具调用强 |
| 4 | Kimi-K2 | - | 多模态强 |
| 5 | Qwen2.5-72B | 720亿 | 开源领先 |
| - | GLM-4-Flash | 旗舰级 | 免费最强 ⭐ |

### 小参数模型对比

| 模型 | 参数量 | 性能评级 | 适用场景 |
|------|--------|---------|---------|
| GLM-4-9B | 90亿 | ⭐⭐⭐ | 中等复杂度任务 |
| Qwen2.5-7B | 70亿 | ⭐⭐ | 简单任务 |
| ChatGLM3-6B | 60亿 | ⭐⭐ | 快速响应 |
| Qwen2-1.5B | 15亿 | ⭐ | 极简任务 |

**关键发现**:
- 7B-9B参数模型性能明显不足
- 与旗舰模型（72B+）差距3-5倍
- 不适合复杂推理、编程等任务

---

## ═══════════════════════════════════════════════════════════════
##                        💡 使用建议
## ═══════════════════════════════════════════════════════════════

### 推荐方案排序

#### 🥇 第一推荐：智谱GLM-4-Flash

**理由**:
- ✅ 官方确认永久免费
- ✅ 性能最强（接近DeepSeek-V3）
- ✅ 128K上下文
- ✅ 支持联网搜索
- ✅ 稳定可靠

**适合**:
- 日常使用（主力模型）
- 复杂任务
- 需要联网的场景
- 个人学习、开发

**配置示例**:
```toml
[[api_providers]]
name = "GLM"
base_url = "https://open.bigmodel.cn/api/paas/v4"
api_key = "your-api-key"

[[models]]
model_identifier = "glm-4-flash"
name = "glm-4-flash"
api_provider = "GLM"
price_in = 0
price_out = 0
```

#### 🥈 第二推荐：硅基流动GLM-4-9B

**理由**:
- ✅ 完全免费
- ✅ 中文能力强
- ✅ 90亿参数（小模型中较强）

**适合**:
- 预算有限的场景
- 中等复杂度任务
- 作为智谱的备选

**限制**:
- ⚠️ 有速率限制
- ⚠️ 性能不如GLM-4-Flash

#### 🥉 第三推荐：DeepSeek（新用户）

**理由**:
- ✅ 性能最强
- ✅ 新用户有免费额度

**不适合**:
- ❌ 长期免费使用（额度用完需付费）
- ❌ 不是真正的免费方案

### 不同场景的模型选择

| 场景 | 推荐模型 | 原因 |
|------|---------|------|
| **日常聊天** | GLM-4-Flash | 免费+性能强 |
| **复杂推理** | GLM-4-Flash | 理解能力强 |
| **编程开发** | GLM-4-Flash | 指令遵循好 |
| **简单任务** | Qwen2.5-7B | 足够使用 |
| **快速响应** | ChatGLM3-6B | 轻量快速 |
| **视觉OCR** | PaddleOCR-VL | 专用免费 |
| **极致性能** | DeepSeek-V3 | 最强但付费 |

---

## ═══════════════════════════════════════════════════════════════
##                        📝 API Key信息
## ═══════════════════════════════════════════════════════════════

### 当前使用的API Key

**智谱AI (GLM)**:
- API Key: `89a2bbde7e784556a0bd2ba1b6403e53.JIYEhnC8GNmW3qte`
- Base URL: `https://open.bigmodel.cn/api/paas/v4`

**硅基流动 (SiliconFlow)**:
- API Key: `sk-idjdrtdithcxuozmairymdebbovithfcidkvnavnchwnxavh`
- Base URL: `https://api.siliconflow.cn/v1`

**DeepSeek**:
- API Key: `sk-d38850098a9540b7a88ded9e311f2a46`
- Base URL: `https://api.deepseek.com`

⚠️ **注意**: API Key已保存在配置文件中，请勿泄露

---

## ═══════════════════════════════════════════════════════════════
##                        🔗 官方文档链接
## ═══════════════════════════════════════════════════════════════

### 智谱AI
- GLM-4-Flash文档: https://docs.bigmodel.cn/cn/guide/models/free/glm-4-flash-250414
- 开放平台: https://open.bigmodel.cn/
- API参考: https://docs.bigmodel.cn/cn/guide/models/text/glm-4.5

### 硅基流动
- 模型列表: https://docs.siliconflow.cn/quickstart/models
- 官方网站: https://siliconflow.cn/
- 定价页面: https://siliconflow.cn/pricing

### 其他平台
- 魔搭社区: https://modelscope.cn/
- DeepSeek: https://www.deepseek.com/
- 讯飞星火: https://xinghuo.xfyun.cn/

---

## ═══════════════════════════════════════════════════════════════
##                        📅 更新日志
## ═══════════════════════════════════════════════════════════════

### 2026-02-03
- ✅ 创建知识库
- ✅ 添加智谱AI GLM-4-Flash文档
- ✅ 添加硅基流动免费模型列表
- ✅ 添加各大平台免费模型对比
- ✅ 添加模型性能基准测试
- ✅ 添加使用建议和配置示例

---

## ═══════════════════════════════════════════════════════════════
##                        💬 使用说明
## ═══════════════════════════════════════════════════════════════

### 如何使用此知识库

**1. 下次对话时**:
- 告诉AI: "读取MCP_KNOWLEDGE_BASE.md"
- AI会直接读取这个文件，获取所有信息
- 不需要重新调用mcp工具

**2. 更新知识库**:
- 当获取新的重要信息时
- 添加到对应的章节
- 更新日期和版本号

**3. 维护建议**:
- 定期检查官方文档是否有更新
- 验证免费模型列表是否还有效
- 更新API Key（如果需要）

---

**知识库版本**: v1.0
**最后更新**: 2026-02-03
**维护者**: hcx185381

